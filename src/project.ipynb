{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca6a837b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Add data to variable 'total data'\n",
    "total_data = pd.read_csv('https://raw.githubusercontent.com/4GeeksAcademy/logistic-regression-project-tutorial/main/bank-marketing-campaign-data.csv', delimiter=';')\n",
    "\n",
    "# Insert raw data inside raw folder inside root.\n",
    "total_data.to_csv('/workspaces/ginotomasd-ml-project-logisticalregression/data/raw/total_data.csv')\n",
    "\n",
    "# Check for columns and rows\n",
    "total_data.shape\n",
    "\n",
    "# Check values inside\n",
    "total_data.info()\n",
    "\n",
    "# We can see that only 1 column contains all the rows, and we fixed that by adding delimiters to our 'total_data' variable.\n",
    "    # Now each variable is stored in an individual column, and we are able to check for nulls\n",
    "        # We do not find any nulls, all columns contain the same number of rows.\n",
    "            # We discard the possibility of duplicates\n",
    "\n",
    "duplicates = total_data.duplicated()\n",
    "print(f\"Number of duplicate rows: {duplicates.sum()}\")\n",
    "\n",
    "total_data[duplicates]\n",
    "\n",
    "# After checking duplicates, we discover they are not duplicates, as they contain different IDs but arent shown because, of the way the data is structured, there is no ID column.\n",
    "\n",
    "# Next step we drop all the data that isn't useful: 'default', 'loan', 'housing', 'duration'\n",
    "\n",
    "filtered_data = total_data.drop(['default', 'loan', 'housing', 'duration' ], axis=1, inplace=True)\n",
    "\n",
    "# Analysis of categorical - numerical data\n",
    "\n",
    "# Categorical data: 'job', 'marital', 'education', 'contact','month', 'day_of_week', 'poutcome', 'y'\n",
    "\n",
    "fig, axis = plt.subplots(2, 4, figsize=(15,7))\n",
    "\n",
    "custom_month_order = ['mar', 'apr', 'may', 'jun', 'jul', 'aug', 'sep', 'oct', 'nov', 'dec']\n",
    "total_data['month'] = pd.Categorical(total_data['month'], categories=custom_month_order, ordered=True)\n",
    "\n",
    "sns.histplot(ax = axis[0,0], data = total_data, x = \"job\")\n",
    "sns.histplot(ax = axis[0,1], data = total_data, x = \"marital\")\n",
    "sns.histplot(ax = axis[0,2], data = total_data, x = \"education\")\n",
    "sns.histplot(ax = axis[0,3], data = total_data, x = \"contact\")\n",
    "sns.histplot(ax = axis[1,0], data = total_data, x = \"month\")\n",
    "sns.histplot(ax = axis[1,1], data = total_data, x = \"day_of_week\")\n",
    "sns.histplot(ax = axis[1,2], data = total_data, x = \"poutcome\")\n",
    "sns.histplot(ax = axis[1,3], data = total_data, x = \"y\")\n",
    "\n",
    "for ax in axis.flat:\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha='right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# As we visualize the data, we can make some observations:\n",
    "    # 'job': The most popular jobs are 'Blue Collar', 'Administrative' and 'Technicians'\n",
    "    # 'marital': As of marital status, there are more single than divorced potential clients, and married clients are the majority.\n",
    "    # 'education': The majority of potential clients have a university degree, and the second most popular category is high school education, comprising almost 50% of the data.\n",
    "    # 'contact': There was almost 66% more contact by cellular phone than telephone \n",
    "    # 'month': We can see that May has the most registered calls, which the next month declined and remained halved until August, when they completely dropped. In November, before Christmas peaked again, but dropped soon after the next month.\n",
    "    # 'day of week': Mondays and Thursdays have the most amount of calls, while Friday had the least amount, although not by much.\n",
    "    # 'poutcome': We can see that most people weren't reached by any previous campaigns, but for those who did, the overwhelming majority was a failure. \n",
    "    # 'y': An overwhelming majority said no to the campaign, while a small minority said otherwhise.\n",
    "\n",
    "\n",
    "# Our next step will be to visualize the numerical data\n",
    "\n",
    "# Numerical data 'age','campaign','pdays','previous','emp.var.rate','cons.price.idx','cons.conf.idx','euribor3m','nr.employed'\n",
    "\n",
    "fig, axis = plt.subplots(3, 4, figsize=(15,7))\n",
    "\n",
    "sns.histplot(ax = axis[0,0], data = total_data, x = \"age\")\n",
    "sns.histplot(ax = axis[0,1], data = total_data, x = \"campaign\")\n",
    "sns.histplot(ax = axis[0,2], data = total_data, x = \"pdays\")\n",
    "sns.histplot(ax = axis[0,3], data = total_data, x = \"previous\")\n",
    "sns.histplot(ax = axis[1,0], data = total_data, x = \"emp.var.rate\")\n",
    "sns.histplot(ax = axis[1,1], data = total_data, x = \"cons.price.idx\")\n",
    "sns.histplot(ax = axis[1,2], data = total_data, x = \"cons.conf.idx\")\n",
    "sns.histplot(ax = axis[1,3], data = total_data, x = \"euribor3m\")\n",
    "sns.histplot(ax = axis[2,0], data = total_data, x = \"nr.employed\")\n",
    "\n",
    "axis[2,1].axis('off')\n",
    "axis[2,2].axis('off')\n",
    "axis[2,3].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# We can make several observations from the visualized data.\n",
    "    # 'age': The majority of the potential clients are comprised within the ages of 20-60yo.\n",
    "    # 'campaign': We observe that the majority of the potential clients are comprised within the 0-5 range, never contacting more than that.\n",
    "    # 'pdays': Representing days since last contact, the overwhelming majority where never contacted the following days, only a few where contacted.\n",
    "    # 'previous': The majority were never contacted before this campaign, while the most contacts made was 2.\n",
    "    # 'emp.var.rate': The employment variation rate is high for positive values, which means the campaigns were performed during an economic growth period, wheree employment rose.\n",
    "    # 'cons.price.idx': Most values are concentrated around 92–94, indicating a narrow spread in the consumer price index during the campaign periods. This stability may suggest low inflation volatility during most campaigns.\n",
    "    # 'cons.conf.idx': Consumer confidence index mostly ranges from -50 to -30, indicating that despite variations, public confidence was generally low, possibly affecting campaign outcomes.\n",
    "    # 'euribor3m': Most values lie above 1.0, peaking near 4.9, suggesting the campaigns mostly occurred during times of relatively high interest rates, which could affect customers’ willingness to invest in term deposits.\n",
    "    # 'nr.employed': The distribution shows most values are clustered around 5000–5200, implying employment levels were relatively high and stable during the majority of the campaigns.\n",
    "\n",
    "# Analysis of multivariate variables\n",
    "\n",
    "# Numerical - Numerical Analysis (Correlation):\n",
    "\n",
    "# Make sure 'y' is numeric\n",
    "total_data['y_num'] = total_data['y'].map({'no': 0, 'yes': 1})\n",
    "\n",
    "# Create a 9x2 subplot\n",
    "fig, axis = plt.subplots(9, 2, figsize=(14, 50))\n",
    "\n",
    "# Plot regplot and heatmap pairs\n",
    "sns.regplot(ax=axis[0, 0], data=total_data, x='y_num', y='age')\n",
    "sns.heatmap(total_data[['y_num', 'age']].corr(), annot=True, ax=axis[0, 1])\n",
    "\n",
    "sns.regplot(ax=axis[1, 0], data=total_data, x='y_num', y='campaign')\n",
    "sns.heatmap(total_data[['y_num', 'campaign']].corr(), annot=True, ax=axis[1, 1])\n",
    "\n",
    "sns.regplot(ax=axis[2, 0], data=total_data, x='y_num', y='pdays')\n",
    "sns.heatmap(total_data[['y_num', 'pdays']].corr(), annot=True, ax=axis[2, 1])\n",
    "\n",
    "sns.regplot(ax=axis[3, 0], data=total_data, x='y_num', y='previous')\n",
    "sns.heatmap(total_data[['y_num', 'previous']].corr(), annot=True, ax=axis[3, 1])\n",
    "\n",
    "sns.regplot(ax=axis[4, 0], data=total_data, x='y_num', y='emp.var.rate')\n",
    "sns.heatmap(total_data[['y_num', 'emp.var.rate']].corr(), annot=True, ax=axis[4, 1])\n",
    "\n",
    "sns.regplot(ax=axis[5, 0], data=total_data, x='y_num', y='cons.price.idx')\n",
    "sns.heatmap(total_data[['y_num', 'cons.price.idx']].corr(), annot=True, ax=axis[5, 1])\n",
    "\n",
    "sns.regplot(ax=axis[6, 0], data=total_data, x='y_num', y='cons.conf.idx')\n",
    "sns.heatmap(total_data[['y_num', 'cons.conf.idx']].corr(), annot=True, ax=axis[6, 1])\n",
    "\n",
    "sns.regplot(ax=axis[7, 0], data=total_data, x='y_num', y='euribor3m')\n",
    "sns.heatmap(total_data[['y_num', 'euribor3m']].corr(), annot=True, ax=axis[7, 1])\n",
    "\n",
    "sns.regplot(ax=axis[8, 0], data=total_data, x='y_num', y='nr.employed')\n",
    "sns.heatmap(total_data[['y_num', 'nr.employed']].corr(), annot=True, ax=axis[8, 1])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Observations:\n",
    "    # There is no positive correlation between any of the variables, in fact, there are some negative correlations between variables.\n",
    "\n",
    "# Categorical -  Categorical Analysis\n",
    "\n",
    "# Categorical variables: 'job', 'marital', 'education', 'contact','month', 'day_of_week', 'poutcome', 'y'\n",
    "\n",
    "categorical_vars = ['job', 'marital', 'education', 'contact', 'month', 'day_of_week', 'poutcome']\n",
    "\n",
    "fig, axes = plt.subplots(2, 4, figsize=(24, 12))\n",
    "axes = axes.flatten()  # Flatten to access as a 1D array\n",
    "\n",
    "for i, var in enumerate(categorical_vars):\n",
    "    sns.countplot(data=total_data, x=var, hue='y', ax=axes[i])\n",
    "    axes[i].set_title(f'Count of {var} grouped by y')\n",
    "    axes[i].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Remove the unused 8th subplot\n",
    "fig.delaxes(axes[-1])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Observations:\n",
    "    # Administrative, blue collar and technicians jobs were the ones who said 'no' and 'yes' the most.\n",
    "    # Marital: Most 'married' said 'no'. 'Single' clients had a higher share of 'yes' responses.\n",
    "    # Education: Higher education levels had slightly better 'yes' rates. 'Basic' education had mostly 'no' responses.\n",
    "    # Contact: Contact by cellular led to more 'yes' responses than telephone.\n",
    "    # Month: Most calls were in May, but better 'yes' rates occurred in March, September, and December.\n",
    "    # Day of Week: Most calls on Monday and Thursday. Slightly better 'yes' rate on Friday.\n",
    "    # Poutcome: Past success in campaigns strongly correlates with a 'yes'. Most had no prior contact or a failed attempt.\n",
    "\n",
    "# Categorical-Numerical Analysis: Boxplots of numerical features grouped by categorical variables and target 'y'\n",
    "\n",
    "# Define categorical and numerical variables\n",
    "categorical_vars = ['job', 'marital', 'education', 'contact', 'month', 'day_of_week', 'poutcome']\n",
    "numerical_vars = ['age', 'campaign', 'pdays', 'previous', 'emp.var.rate','cons.price.idx', 'cons.conf.idx', 'euribor3m', 'nr.employed']\n",
    "\n",
    "# Plot numerical variables against top 3 categorical variables (for brevity and clarity)\n",
    "import itertools\n",
    "fig, axes = plt.subplots(len(numerical_vars), 3, figsize=(20, 35))\n",
    "\n",
    "for i, num_var in enumerate(numerical_vars):\n",
    "    for j, cat_var in enumerate(['job', 'education', 'month']):\n",
    "        sns.boxplot(ax=axes[i, j], data=total_data, x=cat_var, y=num_var, hue='y')\n",
    "        axes[i, j].set_title(f\"{num_var} vs {cat_var}\")\n",
    "        axes[i, j].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Observations:\n",
    "    # Age: Older clients say 'yes' more often in jobs like 'retired' and education levels like 'tertiary'.\n",
    "    # Campaign: Fewer contacts per campaign correlate with more 'yes', regardless of category.\n",
    "    # Pdays: Higher values (recent contact) increase 'yes' rates across most groups.\n",
    "    # Previous: Clients with more past contacts often say 'yes'.\n",
    "    # Emp.var.rate & Euribor3m: Lower values associate with more 'yes' responses.\n",
    "    # Cons.price.idx & Cons.conf.idx: Slight differences by education/month; higher confidence = more 'yes'.\n",
    "    # Nr.employed: Lower values align with more 'yes', likely due to less aggressive market saturation.\n",
    "\n",
    "# 1. Check target variable balance\n",
    "print(\"\\nTarget variable distribution:\")\n",
    "print(total_data['y'].value_counts(normalize=True))\n",
    "\n",
    "# 2. Check correlations heatmap (all numeric features including 'y_num')\n",
    "plt.figure(figsize=(12, 10))\n",
    "corr_matrix = total_data.select_dtypes(include=['number']).corr()\n",
    "sns.heatmap(corr_matrix, annot=True, fmt=\".2f\", cmap='coolwarm')\n",
    "plt.title(\"Correlation matrix of numerical features\")\n",
    "plt.show()\n",
    "\n",
    "# 3. Explore interactions between key categorical variables and target with cross-tab\n",
    "key_cat_vars = ['job', 'marital', 'education', 'contact', 'month', 'day_of_week', 'poutcome']\n",
    "\n",
    "for var in key_cat_vars:\n",
    "    print(f\"\\nCross-tabulation of {var} and target 'y':\")\n",
    "    print(pd.crosstab(total_data[var], total_data['y'], normalize='index').round(3))\n",
    "\n",
    "# 4. Summary statistics grouped by target\n",
    "print(\"\\nSummary statistics for numerical variables by target class:\")\n",
    "print(total_data.groupby('y')[numerical_vars].describe().transpose())\n",
    "\n",
    "# 5. Final check for outliers on numerical variables by target with boxplots\n",
    "\n",
    "fig, axes = plt.subplots(len(numerical_vars), 1, figsize=(12, 30))\n",
    "for i, num_var in enumerate(numerical_vars):\n",
    "    sns.boxplot(x='y', y=num_var, data=total_data, ax=axes[i])\n",
    "    axes[i].set_title(f\"Boxplot of {num_var} by target 'y'\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# We can proceed to preprocessing, feature engineering, and model building next.\n",
    "\n",
    "# Separate target and features\n",
    "X = total_data.drop(columns=['y', 'y_num'])\n",
    "y = total_data['y_num']\n",
    "\n",
    "# Split into train and test sets (stratified to maintain class balance)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Define categorical and numerical columns\n",
    "categorical_features = ['job', 'marital', 'education', 'contact', 'month', 'day_of_week', 'poutcome']\n",
    "numerical_features = ['age', 'campaign', 'pdays', 'previous', 'emp.var.rate', 'cons.price.idx', 'cons.conf.idx', 'euribor3m', 'nr.employed']\n",
    "\n",
    "# Preprocessing pipelines\n",
    "numeric_transformer = StandardScaler()\n",
    "categorical_transformer = OneHotEncoder(drop='first', handle_unknown='ignore')  # drop first to avoid dummy trap\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numerical_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "# Build a pipeline with preprocessing and logistic regression model\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', LogisticRegression(max_iter=1000, random_state=42))\n",
    "])\n",
    "\n",
    "# Train the model\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test set\n",
    "y_pred = pipeline.predict(X_test)\n",
    "y_pred_proba = pipeline.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Evaluation\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()\n",
    "\n",
    "# ROC Curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\n",
    "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, label=f'Logistic Regression (AUC = {roc_auc:.2f})')\n",
    "plt.plot([0,1], [0,1], linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Hyperparameter tuning with GridSearchCV\n",
    "param_grid = {\n",
    "    'classifier__C': [0.01, 0.1, 1, 10, 100],\n",
    "    'classifier__penalty': ['l2'],\n",
    "    'classifier__solver': ['lbfgs']\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='roc_auc', n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"\\nBest parameters from GridSearchCV: {grid_search.best_params_}\")\n",
    "print(f\"Best cross-validation AUC: {grid_search.best_score_:.3f}\")\n",
    "\n",
    "# Evaluate best model on test set\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred_best = best_model.predict(X_test)\n",
    "y_pred_proba_best = best_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"\\nClassification Report (Best Model):\")\n",
    "print(classification_report(y_test, y_pred_best))\n",
    "\n",
    "print(\"\\nConfusion Matrix (Best Model):\")\n",
    "cm_best = confusion_matrix(y_test, y_pred_best)\n",
    "sns.heatmap(cm_best, annot=True, fmt='d', cmap='Greens')\n",
    "plt.title('Confusion Matrix (Best Model)')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()\n",
    "\n",
    "roc_auc_best = roc_auc_score(y_test, y_pred_proba_best)\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, label=f'Initial Model (AUC = {roc_auc:.2f})')\n",
    "fpr_best, tpr_best, _ = roc_curve(y_test, y_pred_proba_best)\n",
    "plt.plot(fpr_best, tpr_best, label=f'Best Model (AUC = {roc_auc_best:.2f})')\n",
    "plt.plot([0,1], [0,1], linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve Comparison')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Checking initial test accuracy:\n",
    "\n",
    "test_accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Test Accuracy (Initial Model): {test_accuracy:.2f}\")\n",
    "\n",
    "# Best test accuracy wiht GridSearch\n",
    "\n",
    "best_test_accuracy = accuracy_score(y_test, y_pred_best)\n",
    "print(f\"Test Accuracy (Best Model): {best_test_accuracy:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
